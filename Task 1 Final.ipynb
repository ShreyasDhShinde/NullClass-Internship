{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total Images Processed: 14886\n"
     ]
    }
   ],
   "source": [
    "# Main folder path\n",
    "IMAGES_FOLDER = r\"C:\\Users\\Shreyash D. Shinde\\imdb_wiki\"\n",
    "\n",
    "# Define subfolders to check\n",
    "SUBFOLDERS = [\"00\", \"01\", \"02\"]\n",
    "\n",
    "#  Lists to store data\n",
    "image_paths = []\n",
    "ages = []\n",
    "\n",
    "# Loop through subfolders\n",
    "for subfolder in SUBFOLDERS:\n",
    "    folder_path = os.path.join(IMAGES_FOLDER, subfolder)\n",
    "\n",
    "    if os.path.exists(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                full_path = os.path.join(folder_path, file)\n",
    "\n",
    "                # Extract birth year & image year using regex\n",
    "                match = re.search(r'_(\\d{4})-\\d+-\\d+_(\\d{4})', file)  # Extract YYYY-MM-DD & image year\n",
    "                if match:\n",
    "                    birth_year = int(match.group(1))  # Extract birth year\n",
    "                    image_year = int(match.group(2))  # Extract image year\n",
    "                    age = image_year - birth_year    # Calculate age\n",
    "                    \n",
    "                    if 0 < age < 100:  # Filter unrealistic ages\n",
    "                        image_paths.append(full_path)\n",
    "                        ages.append(age)\n",
    "\n",
    "# Convert to NumPy array\n",
    "image_paths = np.array(image_paths)\n",
    "ages = np.array(ages, dtype=np.float32)\n",
    "\n",
    "print(f\" Total Images Processed: {len(image_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train Images: 11908, Test Images: 2978\n"
     ]
    }
   ],
   "source": [
    "# Split data into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, ages, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\" Train Images: {len(X_train)}, Test Images: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Image Preprocessing Function\n",
    "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0  # Normalize\n",
    "    return img\n",
    "\n",
    "# Generator for Large Datasets\n",
    "def image_data_generator(image_paths, ages, batch_size=32):\n",
    "    while True:\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_images = [load_and_preprocess_image(img) for img in image_paths[i:i+batch_size]]\n",
    "            batch_ages = ages[i:i+batch_size]\n",
    "            yield np.array(batch_images), np.array(batch_ages, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shreyash D. Shinde\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m6,422,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,516,289</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,516,289\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,516,289</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,516,289\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(1, activation=\"linear\")  # Output age\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 504ms/step - loss: 266.7590 - mae: 12.6850 - val_loss: 167.0864 - val_mae: 10.4997\n",
      "Epoch 2/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 490ms/step - loss: 181.9109 - mae: 10.7216 - val_loss: 166.4901 - val_mae: 10.5020\n",
      "Epoch 3/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 489ms/step - loss: 177.6710 - mae: 10.5824 - val_loss: 161.8023 - val_mae: 10.2435\n",
      "Epoch 4/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 488ms/step - loss: 174.4461 - mae: 10.4859 - val_loss: 159.7610 - val_mae: 10.1092\n",
      "Epoch 5/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 488ms/step - loss: 172.3891 - mae: 10.4214 - val_loss: 160.5275 - val_mae: 10.1106\n",
      "Epoch 6/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 489ms/step - loss: 170.4883 - mae: 10.3731 - val_loss: 163.1418 - val_mae: 10.0866\n",
      "Epoch 7/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 488ms/step - loss: 165.3148 - mae: 10.1909 - val_loss: 163.2819 - val_mae: 10.0674\n",
      "Epoch 8/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 487ms/step - loss: 160.8828 - mae: 10.0322 - val_loss: 165.3509 - val_mae: 10.0805\n",
      "Epoch 9/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 492ms/step - loss: 157.2895 - mae: 9.9127 - val_loss: 160.5955 - val_mae: 9.9668\n",
      "Epoch 10/10\n",
      "\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 486ms/step - loss: 147.0838 - mae: 9.5497 - val_loss: 164.6715 - val_mae: 10.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Create Data Generators\n",
    "train_generator = image_data_generator(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "test_generator = image_data_generator(X_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Train Model\n",
    "model.fit(train_generator, \n",
    "          steps_per_epoch=len(X_train) // BATCH_SIZE, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=test_generator, \n",
    "          validation_steps=len(X_test) // BATCH_SIZE)\n",
    "\n",
    "# Save Model\n",
    "model.save(\"age_detection_model.h5\")\n",
    "print(\" Model Saved Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Loaded Successfully!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"age_detection_model.h5\")\n",
    "print(\" Model Loaded Successfully!\")\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\" Error: Could not load image {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Function to predict age\n",
    "def predict_age(image_path):\n",
    "    input_image = preprocess_image(image_path)\n",
    "    \n",
    "    if input_image is not None:\n",
    "        predicted_age = model.predict(input_image)[0][0]\n",
    "        result_label.config(text=f\"🎯 Predicted Age: {predicted_age:.2f} years\")\n",
    "\n",
    "# Function to open file dialog\n",
    "def select_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    \n",
    "    if file_path:\n",
    "        img = Image.open(file_path)\n",
    "        img.thumbnail((250, 250))  # Resize for display\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "\n",
    "        # Update image display\n",
    "        image_label.config(image=img)\n",
    "        image_label.image = img\n",
    "\n",
    "        # Predict age\n",
    "        predict_age(file_path)\n",
    "\n",
    "# Create GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Age Detection\")\n",
    "\n",
    "# Add a button to select an image\n",
    "select_button = tk.Button(root, text=\" Select Image\", command=select_image)\n",
    "select_button.pack(pady=10)\n",
    "\n",
    "# Label to display selected image\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack()\n",
    "\n",
    "# Label to show prediction result\n",
    "result_label = tk.Label(root, text=\" Predicted Age: --\", font=(\"Arial\", 14))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Run GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
